{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: [3, 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\TIL\\중고차 시세 예측\\중고차 감성분류.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000000?line=2'>3</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000000?line=4'>5</a>\u001b[0m yt_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m./youtube_data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, lineterminator\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m, usecols\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000000?line=5'>6</a>\u001b[0m \u001b[39m#yt_df = yt_df.drop(['내용'], axis=1)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000000?line=6'>7</a>\u001b[0m yt_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1231\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1229'>1230</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1230'>1231</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1231'>1232</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1232'>1233</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:146\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=142'>143</a>\u001b[0m     \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=143'>144</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(usecols):  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=144'>145</a>\u001b[0m         \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=145'>146</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_usecols_names(\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=146'>147</a>\u001b[0m             usecols,\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=147'>148</a>\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnames,  \u001b[39m# type: ignore[has-type]\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=148'>149</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=150'>151</a>\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=151'>152</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_parse_dates_presence(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:913\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[1;34m(self, usecols, names)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=910'>911</a>\u001b[0m missing \u001b[39m=\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m usecols \u001b[39mif\u001b[39;00m c \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m names]\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=911'>912</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=912'>913</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=913'>914</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=914'>915</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=915'>916</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=917'>918</a>\u001b[0m \u001b[39mreturn\u001b[39;00m usecols\n",
      "\u001b[1;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: [3, 4]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "yt_df = pd.read_csv(\"./youtube_data.csv\", lineterminator='\\n')\n",
    "#yt_df = yt_df.drop(['내용'], axis=1)\n",
    "yt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eunjeon import Mecab\n",
    "\n",
    "#형태소 분리 및 품사 태깅\n",
    "tagger=Mecab()\n",
    "significant_tags = ['NNG', 'NNP', 'NNB', 'VV', 'VA', 'VX', 'MAG', 'MAJ', 'XSV', 'XSA']\n",
    "\n",
    "def tagging_text(texts):\n",
    "    corpus = []\n",
    "    for text in texts:\n",
    "        text = tagger.pos(text)\n",
    "        for i in range(len(text)-1):\n",
    "            if text[i][1] in significant_tags:\n",
    "                corpus.append(f\"{text[i][0]}/{text[i][1]}\")\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Wrong number or type of arguments for overloaded function 'Tagger_parse'.\n  Possible C/C++ prototypes are:\n    MeCab::Tagger::parse(MeCab::Model const &,MeCab::Lattice *)\n    MeCab::Tagger::parse(MeCab::Lattice *) const\n    MeCab::Tagger::parse(char const *)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\TIL\\중고차 시세 예측\\중고차 감성분류.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000002?line=0'>1</a>\u001b[0m tagged_corpus \u001b[39m=\u001b[39m tagging_text(yt_df\u001b[39m.\u001b[39;49mcomments)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000002?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000002?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(tagged_corpus[i])\n",
      "\u001b[1;32mc:\\Users\\USER\\TIL\\중고차 시세 예측\\중고차 감성분류.ipynb Cell 2'\u001b[0m in \u001b[0;36mtagging_text\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000001?line=7'>8</a>\u001b[0m corpus \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000001?line=9'>10</a>\u001b[0m     text \u001b[39m=\u001b[39m tagger\u001b[39m.\u001b[39;49mpos(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000001?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(text)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000001?line=11'>12</a>\u001b[0m         \u001b[39mif\u001b[39;00m text[i][\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m significant_tags:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\eunjeon\\_mecab.py:81\u001b[0m, in \u001b[0;36mMecab.pos\u001b[1;34m(self, phrase, flatten)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/eunjeon/_mecab.py?line=78'>79</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/eunjeon/_mecab.py?line=79'>80</a>\u001b[0m     \u001b[39mif\u001b[39;00m flatten:\n\u001b[1;32m---> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/eunjeon/_mecab.py?line=80'>81</a>\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtagger\u001b[39m.\u001b[39;49mparse(phrase)\n\u001b[0;32m     <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/eunjeon/_mecab.py?line=81'>82</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m parse(result)\n\u001b[0;32m     <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/eunjeon/_mecab.py?line=82'>83</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\eunjeon\\mecab.py:465\u001b[0m, in \u001b[0;36mTagger.parse\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/eunjeon/mecab.py?line=463'>464</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/eunjeon/mecab.py?line=464'>465</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _MeCab\u001b[39m.\u001b[39;49mTagger_parse(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Wrong number or type of arguments for overloaded function 'Tagger_parse'.\n  Possible C/C++ prototypes are:\n    MeCab::Tagger::parse(MeCab::Model const &,MeCab::Lattice *)\n    MeCab::Tagger::parse(MeCab::Lattice *) const\n    MeCab::Tagger::parse(char const *)\n"
     ]
    }
   ],
   "source": [
    "tagged_corpus = tagging_text(yt_df.comments)\n",
    "\n",
    "for i in range(5):\n",
    "    print(tagged_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "p1 = re.compile('[가-힣A-Za-z0-9]+/NN. [가-힣A-Za-z0-9]+/XS.')\n",
    "p2 = re.compile('[가-힣A-Za-z0-9]+/NN. [가-힣A-Za-z0-9]+/XSA [가-힣A-Za-z0-9]+/VX')\n",
    "p3 = re.compile('[가-힣A-Za-z0-9]+/VV')\n",
    "p4 = re.compile('[가-힣A-Za-z0-9]+/VX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원형으로 바꾸는 함수\n",
    "def stemming_text(text):\n",
    "    corpus = []\n",
    "    for sent in text:\n",
    "        ori_sent = sent\n",
    "        mached_terms = re.findall(p1, ori_sent)\n",
    "        for terms in mached_terms:\n",
    "            ori_terms = terms\n",
    "            modi_terms = ''\n",
    "            for term in terms.split(' '):\n",
    "                lemma = term.split('/')[0]\n",
    "                tag = term.split('/')[-1]\n",
    "                modi_terms += lemma\n",
    "            modi_terms += '다/VV'\n",
    "            ori_sent = ori_sent.replace(ori_terms, modi_terms)\n",
    "        \n",
    "        mached_terms = re.findall(p2, ori_sent)\n",
    "        for terms in mached_terms:\n",
    "            ori_terms = terms\n",
    "            modi_terms = ''\n",
    "            for term in terms.split(' '):\n",
    "                lemma = term.split('/')[0]\n",
    "                tag = term.split('/')[-1]\n",
    "                if tag != 'VX':\n",
    "                    modi_terms += lemma\n",
    "            modi_terms += '다/VV'\n",
    "            ori_sent = ori_sent.replace(ori_terms, modi_terms)\n",
    "\n",
    "        mached_terms = re.findall(p3, ori_sent)\n",
    "        for terms in mached_terms:\n",
    "            ori_terms = terms\n",
    "            modi_terms = ''\n",
    "            for term in terms.split(' '):\n",
    "                lemma = term.split('/')[0]\n",
    "                tag = term.split('/')[-1]\n",
    "                modi_terms += lemma\n",
    "            if '다' != modi_terms[-1]:\n",
    "                modi_terms += '다'\n",
    "            modi_terms += '/VV'\n",
    "            ori_sent = ori_sent.replace(ori_terms, modi_terms)\n",
    "\n",
    "        mached_terms = re.findall(p4, ori_sent)\n",
    "        for terms in mached_terms:\n",
    "            ori_terms = terms\n",
    "            modi_terms = ''\n",
    "            for term in terms.split(' '):\n",
    "                lemma = term.split('/')[0]\n",
    "                tag = term.split('/')[-1]\n",
    "                modi_terms += lemma\n",
    "            if '다' != modi_terms[-1]:\n",
    "                modi_terms += '다'\n",
    "            modi_terms += '/VV'\n",
    "            ori_sent = ori_sent.replace(ori_terms, modi_terms)\n",
    "        corpus.append(ori_sent)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "법원/NNG\n",
      "교통사고/NNG\n",
      "해/NNG\n",
      "측/NNB\n",
      "보험/NNG\n"
     ]
    }
   ],
   "source": [
    "stem_corpus = stemming_text(tagged_corpus)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print(stem_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['이/VCP','있/VA','하/VV','씨/NNB','것/NNB','들/XSN','그/MM','되/VV','수/NNB','이/NP','속/NNG',\n",
    "'보/VX','않/VX','집/NNG','없/VA','살/VV','나/NP','적/XSN','주/VV','월/NNB','데/NNB','등/NNB','같/VA','안/MAG',\n",
    "'우리/NP','어떤/MM','때/NNG','내/NP','년/NNB','내/VV','가/VV''한/MM','명/NNB','지/VX','오/VV','말/NNG','일/NNG',\n",
    "'앞/NNG','번/NNB','나/VX','두/VV','알/VV','개/NNB','받/VV','전/NNG','들/VV','일/NNB','또/MAG','점/NNG','싶/VX',\n",
    "'더/MAG','말/VX','많/VA','좀/MAG','원/NNB','좋/VA','잘/MAG','크/VA','중/NNB','놓/VX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword_text(text):\n",
    "    corpus = []\n",
    "    for sent in text:\n",
    "        modi_sent = []\n",
    "        for word in sent.split(' '):\n",
    "            if word not in stopwords:\n",
    "                modi_sent.append(word)\n",
    "        corpus.append(' '.join(modi_sent))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "법원/NNG\n",
      "교통사고/NNG\n",
      "해/NNG\n",
      "측/NNB\n",
      "보험/NNG\n"
     ]
    }
   ],
   "source": [
    "removed_stopword_corpus = remove_stopword_text(stem_corpus)\n",
    "\n",
    "for i in range(5):\n",
    "    print(removed_stopword_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>언니 동생으로 부르는게 맞는 일인가요..??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그냥 내 느낌일뿐겠지?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아직너무초기라서 그런거죠?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>유치원버스 사고 낫다던데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>근데 원래이런거맞나요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sentence  Emotion\n",
       "0  언니 동생으로 부르는게 맞는 일인가요..??        0\n",
       "1              그냥 내 느낌일뿐겠지?        0\n",
       "2            아직너무초기라서 그런거죠?        0\n",
       "3             유치원버스 사고 낫다던데        0\n",
       "4               근데 원래이런거맞나요        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df = pd.read_excel(\"./대화_데이터셋.xlsx\")\n",
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23686\n",
      "4180\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(comm_df, test_size=0.15, random_state=3)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion  count\n",
      "0        0  18540\n",
      "1        1   5146\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['Emotion'].value_counts().plot(kind = 'bar')\n",
    "print(train.groupby('Emotion').size().reset_index(name = 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23686\n",
      "4180\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#한글만 남기기\n",
    "train['Sentence'] = train['Sentence'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test['Sentence'] = test['Sentence'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train['Sentence'] = train['Sentence'].str.replace('^ +', \"\")\n",
    "test['Sentence'] = test['Sentence'].str.replace('^ +', \"\")\n",
    "train['Sentence'].replace('', np.nan, inplace = True)\n",
    "test['Sentence'].replace('', np.nan, inplace = True)\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "stopwords = ['이','있','하','씨','것','들','그','되','수','이','속','보','않','집','없','살','나','적','주',\n",
    "'월','데','등','같','안','우리','어떤','때','내','년','내','가''한','명','지','오','말','일','앞','번','나',\n",
    "'두','알','개','받','전','들','일','또','점','싶','더','말','많','좀','원','좋','잘','크','중','놓']\n",
    "okt = Okt()\n",
    "X_train = [] \n",
    "X_test = []\n",
    "\n",
    "# 형태소 분리 및 불용어 제거\n",
    "for sentence in train['Sentence']:\n",
    "    temp_X = okt.morphs(str(sentence), stem = True) \n",
    "    temp_X = [word for word in temp_X if not word in stopwords]\n",
    "    X_train.append(temp_X)\n",
    "    \n",
    "for sentence in test['Sentence']:\n",
    "    temp_X = okt.morphs(str(sentence), stem = True)\n",
    "    temp_X = [word for word in temp_X if not word in stopwords]\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "tokenizer.fit_on_texts(X_test)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y값 분리\n",
    "y_train = train['Emotion']\n",
    "y_test = test['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18942\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "max_len = max(len(l) for l in X_train)\n",
    "print(vocab_size)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         1894200   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               99072     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,110,649\n",
      "Trainable params: 2,110,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "38/38 [==============================] - 271s 7s/step - loss: 0.1754 - acc: 0.7773 - val_loss: 0.1381 - val_acc: 0.7870\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.78704, saving model to LDGD.h5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'h5py' has no attribute 'File'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\TIL\\중고차 시세 예측\\중고차 감성분류.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000022?line=16'>17</a>\u001b[0m mc \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mLDGD.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000022?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39macc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/TIL/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EC%8B%9C%EC%84%B8%20%EC%98%88%EC%B8%A1/%EC%A4%91%EA%B3%A0%EC%B0%A8%20%EA%B0%90%EC%84%B1%EB%B6%84%EB%A5%98.ipynb#ch0000022?line=19'>20</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[es, mc], batch_size\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1220'>1221</a>\u001b[0m   val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1221'>1222</a>\u001b[0m   epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1223'>1224</a>\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_epoch_end(epoch, epoch_logs)\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1224'>1225</a>\u001b[0m training_logs \u001b[39m=\u001b[39m epoch_logs\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=1225'>1226</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:435\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=432'>433</a>\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=433'>434</a>\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=434'>435</a>\u001b[0m   callback\u001b[39m.\u001b[39;49mon_epoch_end(epoch, logs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:1369\u001b[0m, in \u001b[0;36mModelCheckpoint.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1366'>1367</a>\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1367'>1368</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_freq \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1368'>1369</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_model(epoch\u001b[39m=\u001b[39;49mepoch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py:1421\u001b[0m, in \u001b[0;36mModelCheckpoint._save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1417'>1418</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msave_weights(\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1418'>1419</a>\u001b[0m         filepath, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options)\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1419'>1420</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1420'>1421</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49msave(filepath, overwrite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options)\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1421'>1422</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/callbacks.py?line=1422'>1423</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2106\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=2063'>2064</a>\u001b[0m \u001b[39m\"\"\"Saves the model to Tensorflow SavedModel or a single HDF5 file.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=2064'>2065</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=2065'>2066</a>\u001b[0m \u001b[39mPlease see `tf.keras.models.save_model` or the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=2102'>2103</a>\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=2103'>2104</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=2104'>2105</a>\u001b[0m \u001b[39m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=2105'>2106</a>\u001b[0m save\u001b[39m.\u001b[39;49msave_model(\u001b[39mself\u001b[39;49m, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m   <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/engine/training.py?line=2106'>2107</a>\u001b[0m                 signatures, options, save_traces)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py:134\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=127'>128</a>\u001b[0m \u001b[39m# If the user has not already called fit or built the underlying metrics, we\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=128'>129</a>\u001b[0m \u001b[39m# should do that before saving to ensure the metric names have all\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=129'>130</a>\u001b[0m \u001b[39m# appropriate name transformations applied.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=130'>131</a>\u001b[0m saving_utils\u001b[39m.\u001b[39mtry_build_compiled_arguments(model)\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=132'>133</a>\u001b[0m \u001b[39mif\u001b[39;00m (save_format \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mh5\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=133'>134</a>\u001b[0m     (h5py \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath, h5py\u001b[39m.\u001b[39;49mFile)) \u001b[39mor\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=134'>135</a>\u001b[0m     saving_utils\u001b[39m.\u001b[39mis_hdf5_filepath(filepath)):\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=135'>136</a>\u001b[0m   \u001b[39m# TODO(b/130258301): add utility method for detecting model type.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=136'>137</a>\u001b[0m   \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39m_is_graph_network \u001b[39mand\u001b[39;00m  \u001b[39m# pylint:disable=protected-access\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=137'>138</a>\u001b[0m       \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model, sequential\u001b[39m.\u001b[39mSequential)):\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=138'>139</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=139'>140</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mSaving the model to HDF5 format requires the model to be a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=140'>141</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mFunctional model or a Sequential model. It does not work for \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=143'>144</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mto the Tensorflow SavedModel format (by setting save_format=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/USER/anaconda3/lib/site-packages/tensorflow/python/keras/saving/save.py?line=144'>145</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mor using `save_weights`.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'h5py' has no attribute 'File'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GRU(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('LDGD.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[es, mc], batch_size=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('LDGD.h5')\n",
    "print(loaded_model.evaluate(X_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
