{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컴퓨터는 데이터에서 배운다\n",
    "\n",
    "## 머신 러닝의 세 가지 종류\n",
    "- 지도 학습 = 레이블된 데이터, 직접 피드백, 출력 및 미래 예측\n",
    "- 비지도 학습 = 레이블 및 타깃 없음, 피드백 없음, 데이터에서 숨겨진 구조 찾기\n",
    "- 강화 학습 = 결정 과정, 보상 시스템, 연속된 행동에서 학습\n",
    "\n",
    "### 지도 학습으로 미래 예측\n",
    "- 주요 목적 = 레이블된 훈련 데이터에서 모델을 학습하여 본 적 없는 미래 데이터에 대해 예측을 만드는 것\n",
    "- 지도 = 희망하는 출력 신호가 있는 일련의 샘플\n",
    "- 레이블된 훈련 데이터 > 머신 러닝 알고리즘 > 예측 모델 훈련 > 새로운 레이블되지 않은 데이터 입력에 대해 예측 수행\n",
    "- 분류 = 개별 클래스 레이블이 있는 지도 학습\n",
    "- 회귀 = 연속적인 값을 출력\n",
    "\n",
    "#### 분류: 클래스 레이블 예측\n",
    "- 목적 = 과거의 관측을 기반으로 새로운 샘플의 범주형 클래스 레이블을 예측\n",
    "- 클래스 레이블은 이산적이고 순서가 없어 샘플이 속한 그룹으로 이해할 수 있다\n",
    "- 이진 분류 = 두 개의 클래스 레이블을 가지고 분류\n",
    "- 결정 경계 = 이진 분류 시 음성 클래스와 양성 클래스로 레이블되고 두 클래스를 구분할 수 있는 규칙\n",
    "- 다중 분류 = 두 개 이상의 클래스 레이블을 가진 경우\n",
    "\n",
    "#### 회귀: 연속적인 출력 값 예측\n",
    "- 예측 변수(설명 변수)와 연속적인 반응 변수(결과)가 주어졌을 때 출력 값을 예측하기 위해 두 변수 사이의 관계를 찾는다\n",
    "- 예측 변수를 보통 특성이라 부르고, 반응 변수를 타깃이라 부름\n",
    "- 선형 회귀\n",
    "    - 특성 x 와 타깃 y 가 주어지면 데이터 포인트와 직선 사이 거리가 최소과 되는 직선을 그을 수 있다\n",
    "    - 이렇게 데이터에서 학습한 직선의 기울기와 절편을 사용하여 새로운 데이터의 출력 값을 예측\n",
    "\n",
    "### 강화 학습으로 반응형 문제 해결\n",
    "- 목적 = 환경과 상호 작용하여 시스템(에이전트) 성능을 향상하는 것\n",
    "- 환경의 현재 상태 정보는 보상 신호를 포함하기 때문에 강화 학습을 지도 학습과 관련된 분야로 생각할 수 있음\n",
    "- 강화 학습의 피드백은 정답 레이블이나 값이 아닌 보상 함수로 얼마나 행동이 좋은지를 측정한 값\n",
    "- 에이전트는 환경과 상호 작용하여 보상이 최대화되는 일련의 행동을 강화 학습으로 학습\n",
    "- 탐험적인 시행착오 방식이나 신중하게 세운 계획 사용\n",
    "- 일반적인 구조 = 강화 학습 에이전트가 상호 작용하여 보상을 최대화하는 것\n",
    "- 행동을 수행하고 즉시 얻거나 지연된 피드백을 통해 얻은 전체 보상을 최대화하는 일련의 행동을 학습\n",
    "\n",
    "#### 비지도 학습으로 숨겨진 구조 발견\n",
    "- 강화 학습에서는 에이전트의 특정 행동을 보상하는 방법을 정의\n",
    "- 레이블되지 않거나 구조를 알 수 없는 데이터를 다룸\n",
    "- 비지도 학습 기법으로 알려진 출력 값이나 보상 함수의 도움을 받지 않고 의미 있는 정보를 추출하기 위해 데이터 구조를 탐색 가능\n",
    "\n",
    "#### 군집: 서브그룹 찾기\n",
    "- 군집 = 사전 정보 없이 쌓여 있는 그룹 정보를 의미 있는 서브그룹(클러스터)으로 조직하는 탐색적 데이터 분석 기법\n",
    "- 분석 과정에서 만든 각 클러스터는 어느 정도 유사성을 공유하고 다른 클러스터와는 비슷하지 않은 샘플 그룹을 형성\n",
    "- 클러스터링 = 정보를 조직화하고 데이터에서 의미 있는 관계를 유도하는 훌륭한 도구\n",
    "\n",
    "#### 차원 축소: 데이터 압축\n",
    "- 비지도 차원 축소 = 잡음 데이터를 제거하기 위해 특성 전처리 단계에서 종종 적용\n",
    "- 잡음 데이터는 특정 알고리즘의 예측 성능을 감소시킬 수 있다\n",
    "- 차원 축소 = 관련 있는 정보를 대부분 유지하면서 더 작은 차원을 가진 부분 공간으로 데이터를 압축\n",
    "\n",
    "## 기본 용어와 표기법 소개\n",
    "\n",
    "### 머신 러닝 용어\n",
    "- 훈련 샘플 = 데이터셋을 나타내는 테이블의 행, 동의어로 관측, 레코드, 인스턴스, 예시가 있다\n",
    "- 훈련 = 모델 피팅, 모수 모델의 경우 파라미터 추정과 비슷\n",
    "- 특성(x) = 데이터 테이블이나 데이터 행렬의 열, 동의어로 예측 변수, 변수, 입력, 속성, 공변량이 있다\n",
    "- 타깃(y) = 동의어로 결과, 출력, 반응 변수, 종속 변수, (클래스) 레이블, 정답이 있다\n",
    "- 손실 함수 = 종종 비용 함수와 동의어로 사용, 일부 자료에서 손실 함수를 하나의 데이터 포인트에 대해 측정한 손실로 사용하고, 비용 함수는 전체 데이터셋에 대해 계산한 손실(평균 또는 합)로 사용합니다\n",
    "\n",
    "## 머신 러닝 시스템 구축 로드맵\n",
    "\n",
    "### 전처리: 데이터 형태 갖추기\n",
    "- 주어진 원본 데이터의 형태와 모습이 학습 알고리즘이 최적의 성능을 내기에 적합한 경우는 매우 드뭄\n",
    "- 많은 머신 러닝 알고리즘에서 최적의 성능을 내려면 선택된 특성이 같은 스케일을 가져야 한다\n",
    "- 특성을 [0, 1] 범위로 변환\n",
    "- 평균이 0이고 단위 분산을 가진 표준 정규 분포로 변환\n",
    "- 일부 선택된 특성은 매우상관관계가 높아 어느 정도 중복된 정보를 가질 수 있음\n",
    "- 차원 축소 기법을 사용하여 특성을 저차원 부분 공간으로 압축\n",
    "- 특성 공간의 차원을 축소하면 저장 공간이 덜 필요하고 학습 알고리즘을 더 빨리 실행 가능\n",
    "- 어떤 경우에는 차원 축소가 모델으리 예측 성능을 높이기도 함\n",
    "- 데이터셋에 관련 없는 특성(또는 잡음)이 매우 많을 경우, 즉 신호 대 잡음비가 낮은 경우\n",
    "- 머신 러닝 알고리즘이 훈련 데이터셋에서 잘 작동하고 새로운 데이터에서도 잘 일반화되는지 확인하려면 데이터셋을 랜덤하게 훈련 데이터셋과 테스트 데이터셋으로 나누어야 한다\n",
    "- 훈련 데이터셋에서 머신 러닝 모델을 훈련하고 최적화한다\n",
    "- 테스트 데이터셋은 별도로 보관하고 최종 모델을 평가하는 맨 마지막에 사용\n",
    "\n",
    "### 예측 모델 훈련과 선택\n",
    "- 여러 모델을 비교하기 전에 먼저 성능을 측정할 지표를 결정, 분류에서 널리 사용되는 지표는 정확도, 정확도 = 정확히 분류된 샘플 비율\n",
    "- 교차 검증 = 모델의 일반화 성능을 예측하기 위해 훈련 데이터를 훈련 데이터셋과 검증 데이터셋으로 나눔\n",
    "- 모델 성능을 상세하게 조정하기 위해 하이퍼파라미터 최적화 기법 사용\n",
    "- 하이퍼파라미터 = 데이터에서 학습하는 파라미터가 아니라 모델 성능을 향상하기 위해 사용하는 다이얼\n",
    "\n",
    "### 모델을 평가하고 본 적 없는 샘플로 예측\n",
    "- 훈련 데이터셋에서 최적의 모델을 선택한 후에는 테스틑 데이터셋을 사용하여 이전에 본 적이 없는 데이터에서 얼마나 성능을 내는지 예측하여 일반화 오차를 예상\n",
    "- 이 성능에 만족한다면 훈련 데이터셋을 사용해 얻은 파라미터를 테스트 데이터셋은 물론 새로운 모든 샘플을 변환하는데 사용해야 한다, 그렇지 않으면 과도하게 낙관적인 결과가 됨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 분류 알고리즘 훈련\n",
    "\n",
    "## 인공 뉴런: 초기 머신 러닝의 간단한 역사\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
