{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "!pip install -qr yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'yolov5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v7.0-187-g0004c74 Python-3.10.11 torch-2.0.1+cpu CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to yolov5x.pt...\n",
      "100%|██████████| 166M/166M [00:06<00:00, 25.5MB/s] \n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output image saved as output.jpg\n",
      "Detected texts: []\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from yolov5.models.experimental import attempt_load\n",
    "from yolov5.utils.augmentations import letterbox\n",
    "from yolov5.utils.general import non_max_suppression, scale_boxes\n",
    "from yolov5.utils.torch_utils import select_device, time_sync\n",
    "from yolov5.utils.plots import Annotator\n",
    "\n",
    "def process_image(img, imgsz: int):\n",
    "    img = letterbox(img, imgsz)[0]\n",
    "    img = img[:, :, ::-1].copy().transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "    img = torch.from_numpy(img).float()\n",
    "    img = img / 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    return img.unsqueeze(0)\n",
    "\n",
    "def detect_text(weights_path, image_path, imgsz=640, conf_thres=0.25, iou_thres=0.45, names=None):\n",
    "    device = select_device('')  # 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = attempt_load(weights_path, device)  # Load YOLOv5 model\n",
    "\n",
    "    img0 = cv2.imread(image_path)  # Load image as BGR\n",
    "    img = process_image(img0, imgsz).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t1 = time_sync()\n",
    "        pred = model(img, augment=None)[0]\n",
    "\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes=None)\n",
    "\n",
    "    detected_texts = []\n",
    "    for i, det in enumerate(pred):  \n",
    "        if len(det):\n",
    "            det = scale_boxes(img.shape[2:], det, img0.shape)\n",
    "            det[:, :4] = det[:, :4].round()\n",
    "\n",
    "            annotator = Annotator(img0)\n",
    "            for *xyxy, conf, cls in reversed(det):\n",
    "                label = f'{names[int(cls)]} {conf:.2f}'\n",
    "                detected_texts.append(label)\n",
    "                annotator.box_label(xyxy, label)\n",
    "            annotator.im_show()\n",
    "\n",
    "    image_output = \"output.jpg\"\n",
    "    cv2.imwrite(image_output, img0)\n",
    "    print(f\"Output image saved as {image_output}\")\n",
    "    \n",
    "    return detected_texts, img0\n",
    "\n",
    "weights = 'yolov5x.pt'  # Pre-trained model, download from https://github.com/ultralytics/yolov5/releases\n",
    "image_path = '../../data/raw/1687408498051.jpg'  # Input image\n",
    "names = ['text']  # Names of the detected text classes\n",
    "detected_texts, img = detect_text(weights, image_path, names=names, imgsz=1024, conf_thres=0.1)\n",
    "\n",
    "print(\"Detected texts:\", detected_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
